# -*- coding: utf-8 -*-
"""newprojectCI02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17SL-knKWJarLYA6_R_o3sZwev8yX3JRs
"""

#Upload Files
from google.colab import files

uploaded = files.upload()  # Select your CSV or model files to upload

!pip install numpy pandas scikit-learn xgboost catboost lightgbm

#Load the Saved Model
import joblib

# Load the model
model = joblib.load('/content/xgb_model.pkl')
print("Model loaded successfully!")

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder
import joblib

# Load dataset
df = pd.read_csv('hypothyroid.csv')

# Remove rows with "?" values
df = df[(df != "?").all(axis=1)]

# Map target variable
df['binaryClass'] = df['binaryClass'].map({'P': 1, 'N': 0})

# Drop the target variable to get features
X = df.drop('binaryClass', axis=1)

# Encode categorical columns
for col in X.select_dtypes(include='object').columns:
    X[col] = LabelEncoder().fit_transform(X[col])

# Convert to DataFrame after encoding
X = pd.DataFrame(X)

# Impute missing values
imputer = SimpleImputer(strategy='most_frequent')
X = imputer.fit_transform(X)

# Standardize the data
scaler = StandardScaler()
X = scaler.fit_transform(X)

print("Preprocessed data is ready for model predictions.")

# Load the trained model (make sure the model is saved as 'best_model.pkl')
model = joblib.load('/content/xgb_model.pkl')  # Replace 'best_model.pkl' with your model file path

# Check if the model was loaded correctly
print("Model loaded successfully.")

# Make predictions on the preprocessed data
predictions = model.predict(X[:10])  # Predict for the first 10 rows or adjust as needed

# Print the predictions
print("Predictions for sample data:", predictions)

# Optionally, map the predictions back to their original class labels (P or N)
predicted_classes = ['P' if p == 1 else 'N' for p in predictions]
print("Predicted class labels:", predicted_classes)